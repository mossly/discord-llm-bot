"""
Final validation test for the tool calling system
"""
import sys
import os
import asyncio
from unittest.mock import Mock, patch, AsyncMock

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Mock discord and other external dependencies
sys.modules['discord'] = Mock()
sys.modules['discord.ext'] = Mock()
sys.modules['discord.ext.commands'] = Mock()


async def test_tool_system_integration():
    """Test complete tool system integration"""
    print("üîß Testing complete tool system integration...")
    
    # Test that we can import and use the core tool system
    from cogs.tools.base_tool import BaseTool
    from cogs.tools.tool_registry import ToolRegistry
    
    # Create a realistic test tool
    class TestTool(BaseTool):
        @property
        def name(self) -> str:
            return "test_tool"
        
        @property
        def description(self) -> str:
            return "A comprehensive test tool for validation"
        
        @property
        def parameters(self) -> dict:
            return {
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "description": "Action to perform",
                        "enum": ["search", "fetch", "analyze"]
                    },
                    "target": {
                        "type": "string", 
                        "description": "Target for the action"
                    },
                    "options": {
                        "type": "object",
                        "properties": {
                            "limit": {"type": "integer", "minimum": 1, "maximum": 10}
                        }
                    }
                },
                "required": ["action", "target"]
            }
        
        async def execute(self, **kwargs) -> dict:
            action = kwargs.get("action")
            target = kwargs.get("target")
            options = kwargs.get("options", {})
            
            if action == "search":
                return {
                    "success": True,
                    "action": action,
                    "target": target,
                    "results": [f"Result for {target}"],
                    "count": 1
                }
            elif action == "fetch":
                return {
                    "success": True,
                    "action": action,
                    "target": target,
                    "content": f"Content from {target}",
                    "size": len(target) * 10
                }
            elif action == "analyze":
                return {
                    "success": True,
                    "action": action,
                    "target": target,
                    "analysis": f"Analysis of {target}",
                    "confidence": 0.95
                }
            else:
                return {
                    "success": False,
                    "error": f"Unknown action: {action}"
                }
    
    # Test tool creation and registration
    registry = ToolRegistry()
    test_tool = TestTool()
    
    registry.register(test_tool, enabled=True)
    assert registry.is_enabled("test_tool")
    print("‚úÖ Tool registration successful")
    
    # Test complex parameter validation
    error = test_tool.validate_parameters(
        action="search",
        target="test query",
        options={"limit": 5}
    )
    assert error is None
    print("‚úÖ Complex parameter validation successful")
    
    # Test various execution scenarios
    scenarios = [
        {"action": "search", "target": "Python asyncio"},
        {"action": "fetch", "target": "https://example.com"},
        {"action": "analyze", "target": "sample data"},
    ]
    
    for scenario in scenarios:
        result = await registry.execute_tool("test_tool", **scenario)
        assert result["success"] is True
        assert result["action"] == scenario["action"]
        assert result["target"] == scenario["target"]
    
    print("‚úÖ Multiple execution scenarios successful")
    
    # Test error handling
    error_result = await registry.execute_tool("test_tool", action="invalid", target="test")
    assert error_result["success"] is False
    assert "Unknown action" in error_result["error"]
    print("‚úÖ Error handling successful")
    
    # Test OpenAI schema generation for complex parameters
    schema = test_tool.get_openai_schema()
    function_schema = schema["function"]
    
    assert function_schema["name"] == "test_tool"
    assert "enum" in function_schema["parameters"]["properties"]["action"]
    assert "required" in function_schema["parameters"]
    print("‚úÖ Complex schema generation successful")


async def test_chat_integration_simulation():
    """Simulate the tool calling integration with chat system"""
    print("\nü§ñ Testing chat integration simulation...")
    
    # Mock a conversation history with tool calls
    conversation = [
        {"role": "system", "content": "You are a helpful assistant with access to tools."},
        {"role": "user", "content": "Search for information about Python asyncio"},
    ]
    
    # Simulate tool calls that would come from LLM
    simulated_tool_calls = [
        {
            "id": "call_1",
            "type": "function",
            "function": {
                "name": "search_web",
                "arguments": '{"query": "Python asyncio tutorial", "max_results": 3}'
            }
        }
    ]
    
    # Simulate tool results
    simulated_tool_results = [
        {
            "tool_call_id": "call_1",
            "content": """Web search results for 'Python asyncio tutorial':

1. Python Asyncio Documentation
   URL: https://docs.python.org/3/library/asyncio.html
   Asyncio is a library to write concurrent code using async/await syntax.

2. Real Python Asyncio Tutorial  
   URL: https://realpython.com/async-io-python/
   Learn how to use asyncio for asynchronous programming in Python.

3. Asyncio Tutorial - GeeksforGeeks
   URL: https://www.geeksforgeeks.org/asyncio-in-python/
   Complete guide to asyncio with examples and best practices."""
        }
    ]
    
    # Test that this conversation flow would work
    conversation.append({
        "role": "assistant",
        "content": None,
        "tool_calls": simulated_tool_calls
    })
    
    conversation.extend([
        {"role": "tool", "tool_call_id": "call_1", "content": simulated_tool_results[0]["content"]}
    ])
    
    # Simulate final assistant response
    final_response = "Based on the search results, Python asyncio is a library for writing concurrent code using async/await syntax. Here are the key resources I found..."
    
    conversation.append({
        "role": "assistant", 
        "content": final_response
    })
    
    # Validate conversation structure
    assert len(conversation) == 5
    assert conversation[0]["role"] == "system"
    assert conversation[1]["role"] == "user"
    assert conversation[2]["role"] == "assistant"
    assert conversation[3]["role"] == "tool"
    assert conversation[4]["role"] == "assistant"
    
    print("‚úÖ Conversation flow simulation successful")
    print("‚úÖ Tool call integration format validated")


def test_api_integration_readiness():
    """Test that our implementation is ready for OpenAI/OpenRouter APIs"""
    print("\nüåê Testing API integration readiness...")
    
    from cogs.tools.base_tool import BaseTool
    from cogs.tools.tool_registry import ToolRegistry
    
    class APITestTool(BaseTool):
        @property
        def name(self) -> str:
            return "api_test_tool"
        
        @property
        def description(self) -> str:
            return "Test tool for API compatibility"
        
        @property
        def parameters(self) -> dict:
            return {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Query parameter"}
                },
                "required": ["query"]
            }
        
        async def execute(self, **kwargs) -> dict:
            return {"success": True, "data": "test"}
    
    registry = ToolRegistry()
    tool = APITestTool()
    registry.register(tool, enabled=True)
    
    # Test that schemas match OpenAI function calling format
    schemas = registry.get_all_schemas()
    
    for schema in schemas:
        # Validate OpenAI function calling schema format
        required_fields = ["type", "function"]
        for field in required_fields:
            assert field in schema, f"Missing required field: {field}"
        
        assert schema["type"] == "function"
        
        function = schema["function"]
        function_required_fields = ["name", "description", "parameters"]
        for field in function_required_fields:
            assert field in function, f"Missing function field: {field}"
        
        parameters = function["parameters"]
        param_required_fields = ["type", "properties"]
        for field in param_required_fields:
            assert field in parameters, f"Missing parameters field: {field}"
    
    print("‚úÖ OpenAI function calling schema compatibility validated")
    
    # Test JSON serialization compatibility
    import json
    
    try:
        json_schemas = json.dumps(schemas)
        parsed_schemas = json.loads(json_schemas)
        assert len(parsed_schemas) == len(schemas)
        print("‚úÖ JSON serialization compatibility validated")
    except Exception as e:
        print(f"‚ùå JSON serialization failed: {e}")
        raise


async def run_final_validation():
    """Run complete final validation"""
    print("=" * 60)
    print("FINAL VALIDATION - TOOL CALLING SYSTEM")
    print("=" * 60)
    
    try:
        await test_tool_system_integration()
        await test_chat_integration_simulation()
        test_api_integration_readiness()
        
        print("\n" + "=" * 60)
        print("üéâ FINAL VALIDATION SUCCESSFUL!")
        print("=" * 60)
        print("‚úÖ Core tool system working perfectly")
        print("‚úÖ Chat integration simulation passed")
        print("‚úÖ API compatibility validated")
        print("‚úÖ Tool calling system ready for production")
        print("\nüöÄ Ready to deploy!")
        return True
        
    except Exception as e:
        print(f"\n‚ùå Final validation failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(run_final_validation())
    if not success:
        sys.exit(1)